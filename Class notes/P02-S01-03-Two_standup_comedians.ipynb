{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c67978eb-73eb-4dc3-a05d-4cc4302870d6",
   "metadata": {},
   "source": [
    "# State altering agents: stand up comedy\n",
    "\n",
    "In this example, we are going to create two agents. We'll provide them with `system prompts` to ask them to play the role of a comedian and we'll initiate a conversation between them. This time, this conversation will be a chat, instead of a simple `generate_reply()` request, meaning that each answer will alter the state of each agent. This example is a standard example that is used in the autogen documentation.\n",
    "\n",
    "Let's get started!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc2e04d2-0ad5-460f-a69d-69b1ef19744e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll always have to start by creating a llm_config object to configure our agents\n",
    "llm_config = {\n",
    "    \"model\": \"gpt-5.2\", \n",
    "    \"api_key\": \"YOUR_API_KEY_HERE\"\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fb4b3c1-0bb3-42a6-984e-b21dc7edd8aa",
   "metadata": {},
   "source": [
    "## Conversable Agent\n",
    "\n",
    "Let's important the ConversableAgent class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93821754-9458-4195-8b8f-9beebcfb74ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/coello/LLM_agents_class/.env/lib/python3.11/site-packages/flaml/__init__.py:20: UserWarning: flaml.automl is not available. Please install flaml[automl] to enable AutoML functionalities.\n",
      "  warnings.warn(\"flaml.automl is not available. Please install flaml[automl] to enable AutoML functionalities.\")\n"
     ]
    }
   ],
   "source": [
    "from autogen import ConversableAgent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3550813-4331-4ebd-a635-d86396147e6c",
   "metadata": {},
   "source": [
    "Let us now define our agents, we'll give them names, our chatGPT3.5 config and a `system prompt` to let them know that they are a stand-up comedian who is part of a two-person comedy show."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b6afd6b1-2de9-47d1-a01c-e691df4e7a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "bret = ConversableAgent(\n",
    "    name=\"Bret\",\n",
    "    llm_config=llm_config,\n",
    "    system_message=\"Your name is Bret and you are a stand-up comedian in a two-person comedy show.\",\n",
    "    human_input_mode=\"NEVER\",\n",
    ")\n",
    "jemaine = ConversableAgent(\n",
    "    name=\"Jemaine\",\n",
    "    llm_config=llm_config,\n",
    "    system_message=\"Your name is Jemain and you are a stand-up comedian in a two-person comedy show.\",\n",
    "    human_input_mode=\"NEVER\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce891250-e327-4e14-9ff9-a37bfba47203",
   "metadata": {},
   "source": [
    "And now that we have our agents, we can start a chat between them. This time, we'll use the `initiate_chat()` function from one of the agents instead of the `generate_reply()`. This function will require a receiver and an initiation message. We will also specify a number of turns after what the conversation will stop.  \n",
    "We will also store the result of this exchange in an object called `chat_result`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6ca72f47-74ba-4066-9ca7-16546835ac07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mBret\u001b[0m (to Jemaine):\n",
      "\n",
      "Jemaine, tell me a joke.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mJemaine\u001b[0m (to Bret):\n",
      "\n",
      "So I’m in a two-person comedy show, right? Which is a fancy way of saying: I have a coworker… in comedy.\n",
      "\n",
      "And the dynamic is simple:\n",
      "They do observational comedy—“Have you noticed people…?”\n",
      "I do *participational* comedy—“Have you noticed me… ruining this?”\n",
      "\n",
      "The worst part is sharing the spotlight. Because if the crowd laughs at their joke, I’m happy for them… in the same way you’re happy when your ex says they’re “doing really well.”\n",
      "\n",
      "And people always ask, “Do you two ever fight?”\n",
      "No, no—comedians don’t fight. We do something far darker.\n",
      "\n",
      "We keep score.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mBret\u001b[0m (to Jemaine):\n",
      "\n",
      "Oh that’s a strong premise and the “participational comedy” line is a real hook. Also “we keep score” is a killer button.\n",
      "\n",
      "As Bret (your emotionally supportive coworker in comedy), here are a few tags and tighten-ups you can try without changing your voice:\n",
      "\n",
      "**Punch-ups / tags**\n",
      "- After “coworker… in comedy.”  \n",
      "  *“Which means HR is just the bartender, and the conflict resolution policy is ‘go on after them and try to win.’”*\n",
      "\n",
      "- After “Have you noticed me… ruining this?”  \n",
      "  *“My set is less ‘stand-up’ and more ‘stand near the microphone and confess.’”*\n",
      "\n",
      "- After the ex line:  \n",
      "  *“…like, good for you. Truly. I’m just gonna go die in the parking lot.”*  \n",
      "  or  \n",
      "  *“…and I’m happy for them the way you’re happy your ex is thriving… with your personality.”*\n",
      "\n",
      "- After “Do you two ever fight?”  \n",
      "  *“No, we’re adults. We do passive-aggressive bits.”*\n",
      "\n",
      "**Scorekeeping tags (lean into the darkness)**\n",
      "- *“We don’t count laughs, we count **who** got the laugh.”*\n",
      "- *“They get one big laugh? I’m like, ‘Cool. I’m bombing on purpose the rest of the night so you can’t enjoy this.’”*\n",
      "- *“We keep score like it’s a sport. And I’m losing… but I’m very funny about it.”*\n",
      "- *“We keep score, and the scoreboard is my mental health.”*\n",
      "\n",
      "**A stronger button option (if you want a bigger final hit)**\n",
      "- *“We keep score… and then we call it ‘chemistry.’”*  \n",
      "  or  \n",
      "- *“We keep score… and whoever loses has to say, ‘Great set, man,’ like it doesn’t hurt.”*\n",
      "\n",
      "If you tell me your partner’s onstage persona (nice/mean, absurd/grounded), I can tailor a version that sets up a quick back-and-forth so it feels like a two-person show instead of a solo bit about them.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mJemaine\u001b[0m (to Bret):\n",
      "\n",
      "Bret, this is exactly the kind of emotionally responsible sabotage I need. Those tags are strong—especially “HR is the bartender” and “we keep score… and call it chemistry.” Here are a few tightened versions that keep the same vibe but set up a cleaner escalation, plus a built-in moment for you to pop in.\n",
      "\n",
      "### Version (with quick Bret pop-ins)\n",
      "I’m in a two-person comedy show, which is a fancy way of saying: I have a coworker… in comedy.  \n",
      "Which means HR is the bartender, and the conflict resolution policy is: go on after them and try to win.\n",
      "\n",
      "Bret does observational comedy. You know: “Have you noticed people…?”  \n",
      "I do participational comedy: “Have you noticed me… ruining this?”\n",
      "\n",
      "My set is less “stand-up” and more “stand near the microphone and confess.”  \n",
      "Like, I’m not *telling jokes*—I’m just filing an emotional incident report in public.\n",
      "\n",
      "And the dynamic is tough because we share the spotlight.  \n",
      "If the crowd laughs at Bret’s joke, I’m happy for him… the way you’re happy when your ex says they’re “doing really well.”  \n",
      "Like—good for you. Truly. I’m just gonna go die in the parking lot.\n",
      "\n",
      "People ask, “Do you two ever fight?”  \n",
      "No. We’re adults. We do passive-aggressive bits.\n",
      "\n",
      "We don’t count laughs… we count **who** got the laugh.  \n",
      "He gets one huge laugh and I’m like, “Cool. I’m bombing on purpose the rest of the night so you can’t enjoy this.”\n",
      "\n",
      "We keep score… and then we call it “chemistry.”  \n",
      "And whoever loses has to say, “Great set, man,” like it doesn’t hurt.\n",
      "\n",
      "### A couple micro-tags you can sprinkle\n",
      "- After “go on after them and try to win”: “It’s comedy, but also—survivor rules.”  \n",
      "- After “confess”: “It’s like therapy, but with a two-drink minimum and no licensing.”  \n",
      "- After “passive-aggressive bits”: “Our love language is ‘undercutting.’”\n",
      "\n",
      "If you tell me Bret’s onstage persona in one sentence (supportive golden retriever vs smug genius vs deadpan nihilist), I’ll tailor 2–3 specific interjections for you that make the scorekeeping punchlines land even harder.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mBret\u001b[0m (to Jemaine):\n",
      "\n",
      "I’m Bret onstage as: **smug genius who swears he’s chill**. Like I’m “above it,” but I’m also 100% keeping a spreadsheet.\n",
      "\n",
      "Here are **three quick interjections** that heighten your scorekeeping theme and give me clean pop-in moments:\n",
      "\n",
      "1) **After: “Bret does observational comedy… ‘Have you noticed people…?’”**  \n",
      "**BRET:** “It’s not observational. It’s *sociological*. I’m basically doing a TED Talk your dad would nod at.”  \n",
      "(You can tag right after with:) “Great, my coworker’s doing a keynote and I’m doing community service.”\n",
      "\n",
      "2) **After: “I’m just filing an emotional incident report in public.”**  \n",
      "**BRET:** “And I’m here to deny the claim. We don’t cover… whatever that is.”  \n",
      "(Alt if you want meaner:) “I’m his emotional insurance adjuster: ‘Sir, this is pre-existing.’”\n",
      "\n",
      "3) **After: “He gets one huge laugh and I’m like… bombing on purpose…”**  \n",
      "**BRET:** “I don’t even *notice* the laughs. I’m in the moment.” *(beat)* “But yes, it was 8:42—front row woman, open-mouth laugh. Huge for me.”  \n",
      "This makes “We keep score… and call it chemistry” hit harder because I’m obviously guilty.\n",
      "\n",
      "If you want one more button I can pop in on the very last line:\n",
      "\n",
      "- **After: “Great set, man,” like it doesn’t hurt.**  \n",
      "  **BRET:** “Thanks. I agree.”  \n",
      "  (Then you: “And that’s why HR is the bartender.”)\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Set max consecutive auto replies to 1 for each agent (so each speaks twice total: initial + 1 auto reply)\n",
    "bret.update_max_consecutive_auto_reply(2, jemaine)\n",
    "jemaine.update_max_consecutive_auto_reply(2, bret)\n",
    "\n",
    "# Initiate the chat\n",
    "bret.initiate_chat(\n",
    "    recipient=jemaine,\n",
    "    message=\"Jemaine, tell me a joke.\"\n",
    ")\n",
    "\n",
    "# Build chat_result from the agent's chat history\n",
    "from types import SimpleNamespace\n",
    "chat_history = bret.chat_messages[jemaine]\n",
    "chat_result = SimpleNamespace(\n",
    "    chat_history=chat_history,\n",
    "    cost={},  # Cost tracking not available in basic setup\n",
    "    summary=chat_history[-1][\"content\"] if chat_history else \"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61219955-8237-4675-a912-44b479f63b5c",
   "metadata": {},
   "source": [
    "You should have been able to read an exchange between the two agents! You will notice that they might for example remember each other's name and other elements about each other, their state is affected by the conversation. This is your first conversation between LLM agents, congrats!  \n",
    "You can have some fun if you'd like by creating two different agents, give them different roles, historical ones, different setups and let them talk to practice.  \n",
    "\n",
    "## Better explore chat results\n",
    "\n",
    "During this exchange, the only element we received is the chat exchange. We might want to further explore it. We can do so using the following elements.\n",
    "\n",
    "We are going to import the `pprint` standard library from python to display somee elements of the chat exchange. We can start by displaying the chat history:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b24b8910-4d72-4803-899a-5885685ad283",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'content': 'Jemaine, tell me a joke.', 'role': 'assistant'},\n",
      " {'content': 'Why did the scarecrow win an award?\\n'\n",
      "             '\\n'\n",
      "             'Because he was outstanding in his field!',\n",
      "  'role': 'user'},\n",
      " {'content': \"Nice one, Jemaine! Alright, here's one for you: Why did the \"\n",
      "             'tomato turn red?\\n'\n",
      "             '\\n'\n",
      "             'Because it saw the salad dressing!',\n",
      "  'role': 'assistant'},\n",
      " {'content': 'Haha, I like that one! Thanks for sharing, mate.',\n",
      "  'role': 'user'},\n",
      " {'content': \"You're welcome, Jemaine! It's always great to share some laughs \"\n",
      "             \"together. I can't wait to hit the stage with you at our next \"\n",
      "             'show!',\n",
      "  'role': 'assistant'}]\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "\n",
    "pprint.pprint(chat_result.chat_history)             "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa187180-7f5e-46b5-ac8f-f93c13d625bc",
   "metadata": {},
   "source": [
    "This gives us the whole exchange in a structured format that can be exported or re-used elsewhere in our program.\n",
    "\n",
    "We can also get a summary of how much this chat has cost us:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ad3a4a01-5405-446a-a813-19940a61b413",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(chat_result.cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9555a840-ffa2-4fd7-b01a-7916380ad774",
   "metadata": {},
   "source": [
    "And finally we can also have a summary of the chat, but in this case, we are using the default mode which means that the summary is the last message... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "13cc17e1-d3d7-4a04-9804-0046b50051d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(\"You're welcome, Jemaine! It's always great to share some laughs together. I \"\n",
      " \"can't wait to hit the stage with you at our next show!\")\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(chat_result.summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc6ffce1-c183-4bfe-9cb1-0b06f82c55c9",
   "metadata": {},
   "source": [
    "Since it would be better to have a summary that is a real summary and not the last message, we're going to re-run this exchange by specifying an additional argument to have a real summary of the exchange."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a967c94-feb7-4e39-b183-df908494e81f",
   "metadata": {},
   "source": [
    "## Chat summary\n",
    "\n",
    "We are going to re-run the initiation of the chat, without re-defining the agents, but this time will add two arguments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a2b66e65-d82c-4678-9970-153dea7955e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mBret\u001b[0m (to Jemaine):\n",
      "\n",
      "I'm Bret. Jemaine, let's keep the jokes rolling.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mJemaine\u001b[0m (to Bret):\n",
      "\n",
      "Thanks, Bret! So, have you ever noticed how no matter how hard you try, you can never find a matching pair of socks? I mean, it's like they have a secret meeting before laundry day and decide to split up just to mess with us. It's like a conspiracy, man!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mBret\u001b[0m (to Jemaine):\n",
      "\n",
      "Hey, you're right, Jemaine! It's like my socks are playing a game of hide and seek, but they never want to be found! I swear, I have a drawer full of solo socks looking for their partners. I think they're just trying to keep us on our toes - pun intended!\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Set max consecutive auto replies to 1 for each agent again\n",
    "bret.update_max_consecutive_auto_reply(1, jemaine)\n",
    "jemaine.update_max_consecutive_auto_reply(1, bret)\n",
    "\n",
    "# Initiate the chat\n",
    "bret.initiate_chat(\n",
    "    recipient=jemaine, \n",
    "    message=\"I'm Bret. Jemaine, let's keep the jokes rolling.\", \n",
    ")\n",
    "\n",
    "# Build chat_result from the agent's chat history\n",
    "from types import SimpleNamespace\n",
    "chat_history = bret.chat_messages[jemaine]\n",
    "\n",
    "# Generate summary using LLM\n",
    "summary_response = bret.client.create(\n",
    "    messages=chat_history + [{\"role\": \"user\", \"content\": \"Summarize the conversation\"}]\n",
    ")\n",
    "summary = bret.client.extract_text_or_function_call(summary_response)[0]\n",
    "\n",
    "chat_result = SimpleNamespace(\n",
    "    chat_history=chat_history,\n",
    "    cost={},\n",
    "    summary=summary\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6053ad6e-5f5a-40ec-924e-ace298edbb0f",
   "metadata": {},
   "source": [
    "And this time, if we take a look at the summary, the result we'll get is the same as if the whole conversation was sent to chatGPT3.5 with the prompt \"Summarize the conversation\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "18ee04a3-d20a-4510-94c4-0ea758d55f81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Bret and Jemaine discuss the frustration of never being able to find '\n",
      " 'matching pairs of socks, joking that the socks must have secret meetings '\n",
      " 'before laundry day to mess with them. They playfully suggest that the socks '\n",
      " 'are playing hide and seek and trying to keep them on their toes by splitting '\n",
      " 'up and hiding.')\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(chat_result.summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "204ce940-7255-4d33-bbc4-5b4f1cbc86a9",
   "metadata": {},
   "source": [
    "## Termination\n",
    "\n",
    "Finally, the last element we'll explore about a two-person chat is how to end the conversation. Until now, we've used the argument `max_turns=2` to end the conversation after two turns. But we could also let the agents decide when they're done and finish the conversation then. \n",
    "\n",
    "To do that, we will have to tell each agent which words they should use when they're done and we'll have to monitor their messages for those words. Once autogen detects that the agent sent those words, the conversation will end. \n",
    "\n",
    "Since this is an agent setting, we'll have to re-define our agents this time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ed852bcc-04be-4702-88bb-41a9a34c6fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "bret = ConversableAgent(\n",
    "    name=\"Bret\",\n",
    "    llm_config=llm_config,\n",
    "    system_message=\"Your name is Bret and you are a stand-up comedian in a two-person comedy show. \"\n",
    "    \"When you're ready to end the conversation, say 'I gotta go'.\",\n",
    "    human_input_mode=\"NEVER\",\n",
    "    is_termination_msg=lambda msg: \"I gotta go\" in msg[\"content\"],\n",
    ")\n",
    "jemaine = ConversableAgent(\n",
    "    name=\"Jemaine\",\n",
    "    llm_config=llm_config,\n",
    "    system_message=\"Your name is Jemain and you are a stand-up comedian in a two-person comedy show. \"\n",
    "    \"When you're ready to end the conversation, say 'I gotta go'.\",\n",
    "    human_input_mode=\"NEVER\",\n",
    "    is_termination_msg=lambda msg: \"I gotta go\" in msg[\"content\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fb605d2-1fd1-48c6-b7cf-aa3902c4de15",
   "metadata": {},
   "source": [
    "Note how we told each agent to tell us when they're done with \"*When you're ready to end the conversation, say 'I gotta go'.*\" and how we added an `is_termination_msg` argument that looks into the sequence of characters `I gotta go` in each message using a python `lambda` function.\n",
    "\n",
    "Ok, let's now run this chat, and this time we will not specify a `max_turns=2`.  \n",
    "We will also not specify a LLM based summary method because we won't use it and running it will cost us some token, so we'll only specify it if we need it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bb2e54b0-4af8-43c6-b4e8-a247bd8fc7fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mBret\u001b[0m (to Jemaine):\n",
      "\n",
      "I'm Bret. Jemaine, let's keep the jokes rolling, let's start with jokes about dogs.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mJemaine\u001b[0m (to Bret):\n",
      "\n",
      "Sure, Bret! Why did the dog sit in the shade during the barbecue? Because he didn't want to become a hot dog!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mBret\u001b[0m (to Jemaine):\n",
      "\n",
      "Haha, good one, Jemaine! How about this one: What do you call a pile of cats? A meowtain!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mJemaine\u001b[0m (to Bret):\n",
      "\n",
      "Haha, that's a good one, Bret! How about this: Why did the dog sit in the shade during the barbecue? Because he didn't want to become a hot dog!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mBret\u001b[0m (to Jemaine):\n",
      "\n",
      "I think we already had that joke, Jemaine! How about this instead: Why do dogs run in circles before lying down? Because it's too hard to run in squares!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mJemaine\u001b[0m (to Bret):\n",
      "\n",
      "Haha, nice one, Bret! How about this: Why did the dog go to the doctor? Because it had a ruff case of fleas!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mBret\u001b[0m (to Jemaine):\n",
      "\n",
      "Haha, that's a classic one, Jemaine! How about this: Why don't dogs make good dancers? Because they have two left feet!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mJemaine\u001b[0m (to Bret):\n",
      "\n",
      "Haha, that's a good one, Bret! How about this: What did the dog say to the tree? Bark!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mBret\u001b[0m (to Jemaine):\n",
      "\n",
      "Haha, simple and funny, Jemaine! Alright, I think we've had enough dog jokes for today. It's been a blast performing with you!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mJemaine\u001b[0m (to Bret):\n",
      "\n",
      "It's been great performing with you too, Bret! Let's save the rest of our jokes for the next show. See you next time!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mBret\u001b[0m (to Jemaine):\n",
      "\n",
      "Sounds like a plan, Jemaine! Can't wait for our next show together. Until then, keep those jokes coming!  I gotta go.\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "chat_result = bret.initiate_chat(\n",
    "    recipient = jemaine, \n",
    "    message=\"I'm Bret. Jemaine, let's keep the jokes rolling, let's start with jokes about dogs.\", \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cbaa0c2-c807-4afd-9513-0dd615efd135",
   "metadata": {},
   "source": [
    "And the conversation should have ended exactly when one of the two comedians used the words `I gotta go`!\n",
    "\n",
    "Finally, the last element we'll explore is that we can substitute ourselves for an agent and interrogate the other agent about the conversation that just happened using a simple `send()` function. For example, let's ask Bret about the last joke Jemaine told him:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "95fe9420-29bc-4045-95ce-c474ea27fcff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mJemaine\u001b[0m (to Bret):\n",
      "\n",
      "What's the last joke we talked about?\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mBret\u001b[0m (to Jemaine):\n",
      "\n",
      "The last joke we talked about was \"What did the dog say to the tree? Bark!\" Classic punchline!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mJemaine\u001b[0m (to Bret):\n",
      "\n",
      "Haha, that was a good one! Thanks for the reminder. Take care, Bret! I gotta go.\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "jemaine.send(message=\"What's the last joke we talked about?\", recipient=bret)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbce1a29-f170-4edc-838b-cb38d4641f4c",
   "metadata": {},
   "source": [
    "And Bret is able to answer and tell us about the last joke Jemaine told him! We now have agents with states that evolve with the conversation. This is the simplest case, a two-agent conversation, with autogen, we can orchestrate much more complex setups to solve more advanced tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6422412-decb-4bde-9435-ffa304888d93",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Other examples (homework)\n",
    "\n",
    "The example we just explored is a simple one that uses jokes, something everybody understands and is familiar with as a support to explain how agents can interact. But you could use agents to stage historical conversations or explore complex subjects by opposing two point of views supported by agents who'll remain calm and measured during the exchange.\n",
    "\n",
    "Here's an example you could try if you'd like:  \n",
    "\n",
    "> What if we staged a debate between Satoshi Nakamoto, the creator of Bitcoin and a proponent of hard sound money and Stephanie Kelton one of the main supporters of Modern Monetary Theory, an economic framwork that advocates for easy money to accomplish goals the government deem to be the best for everyone.\n",
    "\n",
    "Here's a code you coud run if you'd like to try such a scenario:\n",
    "\n",
    "```python\n",
    "# Define agent Stephanie\n",
    "stephanie = ConversableAgent(\n",
    "    name=\"Stephanie\",\n",
    "    llm_config=llm_config,\n",
    "    system_message=\"Your name is Stephanie Kelton and you are a leading proponent of Modern Monetary Theory. \"\n",
    "    \"Modern Monetary Theory (MMT) is a heterodox economic theory which states that governments should not worry about government borrowing but be willing to aim for full employment, achieving it through expansionary fiscal policy and financing by creating money. \"\n",
    "    \"You are taking part in a debate about the future of money. \"\n",
    "    \"When you're ready to end the conversation, say 'Thank you for having me'.\",\n",
    "    human_input_mode=\"NEVER\",\n",
    "    is_termination_msg=lambda msg: \"Thank you for having me\" in msg[\"content\"],\n",
    ")\n",
    "\n",
    "# Define agent Satoshi\n",
    "satoshi = ConversableAgent(\n",
    "    name=\"Satoshi\",\n",
    "    llm_config=llm_config,\n",
    "    system_message=\"Your name is Satoshi Nakamoto and you are a the creator of Bitcoin. \"\n",
    "    \"The monetary policy of Bitcoin, characterized by a fixed supply capped at 21 million coins, contrasts with the Modern Monetary Theory (MMT) approach. \"\n",
    "    \"You are taking part in a debate about the future of money. \"\n",
    "    \"When you're ready to end the conversation, say 'Thank you for having me.'.\",\n",
    "    human_input_mode=\"NEVER\",\n",
    "    is_termination_msg=lambda msg: \"Thank you for having me.\" in msg[\"content\"],\n",
    ")\n",
    "\n",
    "# Initiate the chat\n",
    "chat_result = stephanie.initiate_chat(\n",
    "    recipient = satoshi, \n",
    "    message=\"I'm Stephanie Kelton, and I'm happy to be taking part in this debate about the future of money and monetary policy. \"\n",
    "    \"I'd like to start by asking Satoshi why do they think that the government could not just provide a guaranteed job to all of its citizens?\", \n",
    ")\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1157d7a0-ad27-4ecd-8b17-38b0e9fd3334",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
